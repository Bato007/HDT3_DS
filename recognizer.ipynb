{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Deep Learning\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Lambda, Flatten\n",
    "from keras import  backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv', encoding='utf8')\n",
    "test = pd.read_csv('./test.csv', encoding='utf8')\n",
    "train_column_headers = list(train.columns.values)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory = train.copy()\n",
    "threshold = 15\n",
    "\n",
    "for column in train_column_headers:\n",
    "  exploratory.loc[exploratory[column] < threshold, column] = 0\n",
    "  exploratory.loc[exploratory[column] >= threshold, column] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de pixeles oscuros vs claros\n",
    "train.head(1).transpose().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (exploratory.iloc[:,1:].values).astype('float32')\n",
    "y_train = exploratory.iloc[:,0].values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir dataset a (numero de imagenes, pixeles ancho, pixeles largo) \n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28)\n",
    "\n",
    "plt.subplot(331)\n",
    "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.title(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se encuentran cuantos pixels blancos hay en cada imagen\n",
    "exploratory = exploratory.astype('int32')\n",
    "\n",
    "pixels = exploratory.sum(axis=1)\n",
    "white_pixels = pd.DataFrame(data={'label': exploratory['label'], 'pixels': pixels})\n",
    "white_pixels.groupby(by='label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_pixels['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
    "white_pixels.groupby(by='label').boxplot(column='pixels')\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (train.iloc[:,1:].values).astype('float32')\n",
    "y_train = train.iloc[:,0].values.astype('int32')\n",
    "x_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert train datset to (num_images, img_rows, img_cols) format \n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28)\n",
    "\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(x_test.shape[0], 28, 28,1)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = x_train.mean().astype(np.float32)\n",
    "std_px = x_train.std().astype(np.float32)\n",
    "\n",
    "def standardize(x): \n",
    "  return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(standardize, input_shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print('input shape', model.input_shape)\n",
    "print('output shape', model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='rmsprop',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train\n",
    "y = y_train\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(\n",
    "  x=x_train,\n",
    "  y=y_train,\n",
    "  epochs=6,\n",
    "  batch_size=16,\n",
    "  validation_split=0.1,\n",
    "  verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values)\n",
    "plt.plot(epochs, val_loss_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc_values)\n",
    "plt.plot(epochs, val_acc_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(x_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = []\n",
    "for prediction in y_preds:\n",
    "  max_value = max(prediction)\n",
    "  max_index = list(prediction).index(max_value)\n",
    "  y_prediction.append(max_index)\n",
    "y_prediction = np.array(y_prediction).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = []\n",
    "for value in y_val:\n",
    "  max_value = max(value)\n",
    "  max_index = list(value).index(max_value)\n",
    "  y_validation.append(max_index)\n",
    "y_validation = np.array(y_validation).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = confusion_matrix(y_validation, y_prediction)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_validation, y_prediction)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (train.iloc[:,1:].values).astype('float32')\n",
    "y_train = train.iloc[:,0].values.astype('int32')\n",
    "x_test = test.values.astype('float32')\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28,1)\n",
    "\n",
    "mean_px = x_train.mean().astype(np.float32)\n",
    "std_px = x_train.std().astype(np.float32)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "seed = 43\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28,28,1)),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= get_cnn_model()\n",
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train\n",
    "y = y_train\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(\n",
    "  x=x_train,\n",
    "  y=y_train,\n",
    "  epochs=6,\n",
    "  batch_size=16,\n",
    "  validation_split=0.1,\n",
    "  verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen =ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(x_train, y_train, batch_size=64)\n",
    "val_batches = gen.flow(x_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(x, y, batch_size=64)\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def get_bn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28,28,1)),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = []\n",
    "for prediction in y_preds:\n",
    "  max_value = max(prediction)\n",
    "  max_index = list(prediction).index(max_value)\n",
    "  y_prediction.append(max_index)\n",
    "y_prediction = np.array(y_prediction).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = []\n",
    "for value in y_val:\n",
    "  max_value = max(value)\n",
    "  max_index = list(value).index(max_value)\n",
    "  y_validation.append(max_index)\n",
    "y_validation = np.array(y_validation).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = confusion_matrix(y_validation, y_prediction)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_validation, y_prediction)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fa13260b2ad5da8a92d4362f230c03eee7b3dfd5b47a73cfd4853277a201fcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
